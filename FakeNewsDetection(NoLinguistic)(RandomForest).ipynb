{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNewsDetection(NoLinguistic)(RandomForest).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYGvYUGJBLoM",
        "outputId": "087e22f5-6446-4b0f-b059-163b1dd22d43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYXQhmctBaja"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMo_t0wzpoVs"
      },
      "source": [
        "def clean_text(text):\n",
        "    if text:\n",
        "        text = f'{text}'\n",
        "        text = text.lower()\n",
        "        text = text.split()\n",
        "        ps = PorterStemmer()\n",
        "        text = [ps.stem(word) for word in text if text not in stopwords.words('english')]\n",
        "        text = ' '.join(text)\n",
        "        return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL_vGeklBgJc",
        "outputId": "ab83388f-43c6-44a0-8675-f986fe57677c"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sJ7RN6wBdHo"
      },
      "source": [
        "#Import dataset 1 (First 5000 samples)\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/train.csv\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(5000):\n",
        "  X.append(clean_text(data['title'][i]))\n",
        "  y.append(data['label'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66ahcwHMr9tD"
      },
      "source": [
        "#Import dataset 2 (First 5000 samples)\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/fake_or_real_news.csv\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(5000):\n",
        "    X.append(clean_text(data['title'][i]))\n",
        "    if data['label'][i] == 'FAKE':\n",
        "        y.append(0)\n",
        "    else:\n",
        "        y.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE_wTrxotML7"
      },
      "source": [
        "#Import dataset 3\n",
        "fake_data = pd.read_csv(\"/content/gdrive/MyDrive/Fake.csv\",engine = 'python')\n",
        "true_data = pd.read_csv(\"/content/gdrive/MyDrive/True.csv\",engine = 'python')\n",
        "\n",
        "#Take 2500 samples from true data , 4064 samples from fake data\n",
        "X = []\n",
        "y = []\n",
        "for i in range(4064):\n",
        "    X.append(clean_text(fake_data['title'][i]))\n",
        "    y.append(0)\n",
        "for i in range(2500):\n",
        "    X.append(clean_text(true_data['title'][i]))\n",
        "    y.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Lewoa17zML"
      },
      "source": [
        "#Import dataset 4 (7950 samples)\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "fake_data = pd.read_csv(\"/content/gdrive/MyDrive/Fake.csv\",engine = 'python')\n",
        "fake_data_2 = pd.read_csv(\"/content/gdrive/MyDrive/fake2.csv\",engine = 'python')\n",
        "true_data = pd.read_csv(\"/content/gdrive/MyDrive/True.csv\",engine = 'python')\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(1620):\n",
        "    X.append(clean_text(fake_data['title'][i]))\n",
        "    y.append(0)\n",
        "for i in range(2880):\n",
        "    X.append(clean_text(fake_data_2['title'][i]))\n",
        "    y.append(0)\n",
        "for i in range(3450):\n",
        "    X.append(clean_text(true_data['title'][i]))\n",
        "    y.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xGwqeny-He6",
        "outputId": "f660cb78-7559-484a-acda-de9f8aae9969"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7950"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFSsEktrpLUN"
      },
      "source": [
        "#Import dataset 5 (185 samples)\n",
        "X  = []\n",
        "y = []\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/special_fake_news.txt\",'r',encoding = 'latin-1') as file:\n",
        "    texts = file.read().split('\\n')\n",
        "    for text in texts:\n",
        "        if text:\n",
        "            X.append(clean_text(text))\n",
        "            y.append(0)\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/special_real_news.txt\",'r',encoding = 'latin-1') as file:\n",
        "    texts = file.read().split('\\n')\n",
        "    for text in texts:\n",
        "        if text:\n",
        "            X.append(clean_text(text))\n",
        "            y.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_aLiAUlUaM"
      },
      "source": [
        "#Import dataset 6\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/data.csv\")\n",
        "X = []\n",
        "y = data['Label']\n",
        "for i in range(len(data)):\n",
        "    X.append(clean_text(data['Headline'][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG6q1AKypMIP"
      },
      "source": [
        "#Import dataset 7 \n",
        "X = []\n",
        "y = []\n",
        "\n",
        "#Get 2000 samples from dataset 6 \n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/data.csv\")\n",
        "for i in range(2000):\n",
        "    X.append(clean_text(data['Headline'][i]))\n",
        "    y.append(data['Label'][i])\n",
        "\n",
        "#Get all from dataset 5\n",
        "with open(\"/content/gdrive/MyDrive/special_fake_news.txt\",'r',encoding = 'latin-1') as file:\n",
        "    texts = file.read().split('\\n')\n",
        "    for text in texts:\n",
        "        if text:\n",
        "            X.append(clean_text(text))\n",
        "            y.append(0)\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/special_real_news.txt\",'r',encoding = 'latin-1') as file:\n",
        "    texts = file.read().split('\\n')\n",
        "    for text in texts:\n",
        "        if text:\n",
        "            X.append(clean_text(text))\n",
        "            y.append(1)\n",
        "\n",
        "#Get 2000 samples from dataset 1\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/train.csv\")\n",
        "for i in range(5000):\n",
        "  X.append(clean_text(data['title'][i]))\n",
        "  y.append(data['label'][i])\n",
        "\n",
        "#Get 3000 samples from dataset 3\n",
        "fake_data = pd.read_csv(\"/content/gdrive/MyDrive/Fake.csv\",engine = 'python')\n",
        "true_data = pd.read_csv(\"/content/gdrive/MyDrive/True.csv\",engine = 'python')\n",
        "\n",
        "#Take 1100 samples from true data , 1900 samples from fake data\n",
        "for i in range(1100):\n",
        "    X.append(clean_text(fake_data['title'][i]))\n",
        "    y.append(0)\n",
        "for i in range(1900):\n",
        "    X.append(clean_text(true_data['title'][i]))\n",
        "    y.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fasEegOoCxe",
        "outputId": "3aa9f0bb-b156-4b78-9eef-2175a6cdbc7d"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v78AULGwBtbu"
      },
      "source": [
        "corpus = []\n",
        "for i in range(len(data)):\n",
        "    title = f\"{data['title'][i]}\"\n",
        "    corpus.append(clean_text(title))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3vUkQ5tCB-4"
      },
      "source": [
        "#Features selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq0tQLyPCFM1"
      },
      "source": [
        "#Split test set\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y, test_size = 0.30,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr0KOVSECNTI"
      },
      "source": [
        "#Classification(RandomForest)\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "rf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
        "rf = rf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJiI0Vl6Cf5E"
      },
      "source": [
        "rf_y_pred = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5qtGxNADVNx"
      },
      "source": [
        "#Making confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "rf_cm = confusion_matrix(y_test , rf_y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWb28_yoDfCU"
      },
      "source": [
        "def calculate_accuracy(cm):\n",
        "    tn = cm[0][0]\n",
        "    tp = cm[1][1]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "        \n",
        "    accuracy = (tn + tp) / (tn + tp + fp + fn)\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    f1 = 2*(precision*recall)/(precision + recall)\n",
        "    average = (accuracy + precision + recall + f1) /4 \n",
        "    return [accuracy , precision , recall , f1 , average]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fk0ciE_DiiZ"
      },
      "source": [
        "rf_acc = calculate_accuracy(rf_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RovWf9iDnMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f321e991-3af3-43ad-c5b4-328d5e25cee0"
      },
      "source": [
        "rf_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8436471362738643,\n",
              " 0.7895287958115184,\n",
              " 0.9538266919671095,\n",
              " 0.8639358350042967,\n",
              " 0.8627346147641972]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkm9Q_4nyLxO",
        "outputId": "0ddbd2ac-8765-48e3-d36f-9c2b3a52239a"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}